{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"BAIT\"\n",
        "format: \n",
        "    html:\n",
        "        code-fold: true\n",
        "---"
      ],
      "id": "a4d9c181"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reporting"
      ],
      "id": "f59870a8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import geopandas as gpd\n",
        "from shapely import wkb\n",
        "from dotenv import load_dotenv\n",
        "import awswrangler as wr\n",
        "import os\n",
        "import yaml\n",
        "import boto3\n",
        "from IPython import display as ICD"
      ],
      "id": "02d12bdd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configs\n",
        "# load environment variables with\n",
        "load_dotenv()\n",
        "\n",
        "# import config\n",
        "with open(\"../config.yaml\") as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# connect to AWS with credentials\n",
        "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "AWS_REGION = os.getenv(\"REGION\")\n",
        "BUCKET = os.getenv(\"BUCKET\")\n",
        "FOLDER = config[\"aws\"][\"folder\"]\n",
        "\n",
        "# connect to AWS\n",
        "session = boto3.Session(\n",
        "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
        "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
        "    region_name=AWS_REGION\n",
        ")\n",
        "s3 = session.client(\"s3\")"
      ],
      "id": "80ccf5ea",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# S1: Get User Data\n",
        "# get users data from S3\n",
        "gdf_users = (\n",
        "    wr.s3.read_parquet(\n",
        "        f\"s3://{BUCKET}/{FOLDER}/{config['aws']['users-file']}\"\n",
        "    )\n",
        "    .rename(columns={\"client_latitude\": \"latitude\", \"client_longitude\": \"longitude\"})\n",
        "    # convert to GeoDataFrame\n",
        "    .pipe(gpd.GeoDataFrame)\n",
        "    .assign(\n",
        "        geometry=lambda x: gpd.points_from_xy(x['longitude'], x['latitude'])\n",
        "    )\n",
        "    .set_crs(epsg=4326)\n",
        ")\n",
        "\n",
        "# S2: Wrangle Data\n",
        "# eliminate invalid values of raw_sim_operator_name\n",
        "non_valid_operators = config['report']['non-valid-operators']\n",
        "gdf_users = gdf_users[~gdf_users[\"raw_sim_operator_name\"].isin(non_valid_operators)]\n",
        "\n",
        "# standarize the name of Megacable\n",
        "gdf_users.loc[\n",
        "    gdf_users[\"raw_sim_operator_name\"].isin([\"Mega 4.5G\", \"Mega4.5G\"]), \"raw_sim_operator_name\"\n",
        "    ] = \"Megacable\""
      ],
      "id": "b0dac3e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# S1: Get Shape Data\n",
        "# download shapefile of states\n",
        "gdf_states = (\n",
        "    wr.s3.read_parquet(\n",
        "        f\"s3://{BUCKET}/{FOLDER}/{config['aws']['states-file']}\"\n",
        "    )\n",
        "    # pass geometry column from binary to geometry\n",
        "    .assign(geometry=lambda x: x['geometry'].apply(wkb.loads))\n",
        "    .pipe(gpd.GeoDataFrame)\n",
        "    .set_crs(epsg=4326)\n",
        "    .rename(columns={\"CODIGO\": \"cve_ent\", \"ESTADO\": \"cve_name\"})\n",
        "    .assign(\n",
        "        cve_ent=lambda x: x['cve_ent'].str[-2:],\n",
        "        cve_name=lambda x: x['cve_name'].str.lower()\n",
        "    )\n",
        "    .sort_values('cve_ent', ignore_index=True)\n",
        ")\n",
        "\n",
        "# S2: Wrangle Data\n",
        "# get data of walmart stores\n",
        "re_walmart = r\"(walmart|wal mart|superama|waltmart)\"\n",
        "re_sams = r\"(sams|sam's|sam s|sam's club|sam s club|sam'sclub|sam sclub|sam club|mi bodega)\"\n",
        "re_bodega = r\"(bodega aurrera|bodega|aurrera|ba|boa|\\$b|mb|b )\"\n",
        "re_supercenter = r\"(supercenter|super center)\"\n",
        "\n",
        "# get walmart stores\n",
        "gdf_walmart = (\n",
        "    wr.s3.read_csv(\n",
        "        f\"s3://{BUCKET}/{FOLDER}/{config['aws']['walmart-file']}\"\n",
        "    )\n",
        "    .assign(\n",
        "        geometry=lambda x: gpd.points_from_xy(x['longitude'], x['latitude']),\n",
        "        # get bodega aurrera or walmart or sams in name\n",
        "        store_name=lambda x: np.select(\n",
        "            [\n",
        "                x['name'].str.contains(re_bodega, case=False),\n",
        "                x['name'].str.contains(re_walmart, case=False),\n",
        "                x['name'].str.contains(re_sams, case=False),\n",
        "                x['name'].str.contains(re_supercenter, case=False)\n",
        "            ],\n",
        "            ['bodega aurrera', 'walmart', 'sams', 'supercenter'],\n",
        "            default='other'\n",
        "        )\n",
        "    )\n",
        "    .pipe(gpd.GeoDataFrame, crs=\"EPSG:4326\")\n",
        "    .query(\"store_name != 'other'\")\n",
        "    .loc[:, [\n",
        "             'id', 'store_name', 'name', 'staff_stratum_description',\n",
        "             'postal_code', 'cve_ent', 'cve_mun', 'geometry'\n",
        "            ]]\n",
        ")"
      ],
      "id": "1a5a8d0d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# S1: Get Connections Data\n",
        "# get connections data from S3\n",
        "gdf_connections = (\n",
        "    wr.s3.read_parquet(\n",
        "        f\"s3://{BUCKET}/{FOLDER}/{config['aws']['connections-file']}\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# S2: Wrangle Data\n",
        "# obtain the day of the week of each test\n",
        "gdf_connections['day_of_week'] = gdf_connections['result_date'].dt.day_name()"
      ],
      "id": "04a75dd3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Participación de mercado\n"
      ],
      "id": "8d255841"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Join Data\n",
        "# join users with states\n",
        "tbl_users_state = (\n",
        "    gpd.sjoin_nearest(\n",
        "        gdf_users.to_crs(\"EPSG:6372\"), gdf_states.to_crs(\"EPSG:6372\"),\n",
        "    )\n",
        "    .drop_duplicates(subset=[\"device_id\"])\n",
        "    .filter([\"device_id\", \"postal_code\", \"raw_sim_operator_name\", \"cve_name\"])\n",
        ")\n",
        "\n",
        "# define the dictionary\n",
        "nielsen_zones = config['report']['nielsen_zones']\n",
        "\n",
        "# map the states to their corresponding regions\n",
        "tbl_users_state['region'] = (\n",
        "    tbl_users_state['cve_name']\n",
        "    .map(\n",
        "        lambda x: next((region for region, states in nielsen_zones.items() if x.lower() in states), None)\n",
        "        )\n",
        ")\n",
        "\n",
        "# droup by 'raw_sim_operator_name' and count 'device_id', then sort and get the top 10\n",
        "top_operators = (\n",
        "    tbl_users_state\n",
        "    .groupby([\"raw_sim_operator_name\"])['device_id']\n",
        "    .count()\n",
        "    .sort_values(ascending=False)\n",
        "    .head(10)\n",
        "    .reset_index()\n",
        "    [\"raw_sim_operator_name\"]\n",
        ")\n",
        "\n",
        "# Wrangle\n",
        "tbl_users_state.loc[~tbl_users_state[\"raw_sim_operator_name\"].isin(top_operators), \"raw_sim_operator_name\"] = \"other\"\n",
        "# group by 'raw_sim_operator_name' and count 'device_id'\n",
        "df_top_operator = tbl_users_state.groupby([\"raw_sim_operator_name\", \"region\"])['device_id'].count().reset_index()\n",
        "# Get market share\n",
        "df_top_operator[\"market_share\"] = df_top_operator.groupby(\"region\")[\"device_id\"].transform(lambda x: x / x.sum())\n",
        "# Pivot the DataFrame for the stacked bar chart\n",
        "pivot_df = df_top_operator.pivot(index='region', columns='raw_sim_operator_name', values='market_share')\n",
        "# Fill NaN values with 0\n",
        "pivot_df = pivot_df.fillna(0)\n",
        "\n",
        "# Plot\n",
        "# stacked bar chart\n",
        "pivot_df.plot(kind='bar', stacked=True, figsize=(12, 8), colormap='tab20')\n",
        "# add labels and title\n",
        "plt.xlabel('Estado')\n",
        "plt.ylabel('Device ID Count')\n",
        "plt.title('Top 10 SIM Operators by Device ID Count per Estado')\n",
        "plt.legend(title='SIM Operator Name', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "# y lim\n",
        "plt.ylim(0, 1)\n",
        "# y in percentage\n",
        "plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_yticks()])\n",
        "# display\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "4c601a79",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Presencia nacional"
      ],
      "id": "fc1debb8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Select only BAIT users\n",
        "gdf_bait_users = gdf_users[gdf_users[\"raw_sim_operator_name\"] == \"BAIT\"]\n",
        "\n",
        "# Join users with stores getting the closest store\n",
        "gdf_clients_stores = (\n",
        "    gpd.sjoin_nearest(\n",
        "        gdf_bait_users.to_crs(\"EPSG:6372\"), gdf_walmart.to_crs(\"EPSG:6372\"),\n",
        "    )\n",
        "    .drop_duplicates(subset=[\"device_id\"])\n",
        "    .groupby([\"name\", \"store_name\", \"id\", \"cve_ent\", \"cve_mun\"])\n",
        "    .agg(\n",
        "        count=(\"device_id\", \"count\")\n",
        "    )\n",
        "    .reset_index()\n",
        "    .sort_values(\"count\", ascending=False)\n",
        "    .merge(\n",
        "        gdf_walmart.loc[:, [\"id\", \"geometry\"]],\n",
        "        on=\"id\",\n",
        "        how=\"left\"\n",
        "    )\n",
        "    .pipe(gpd.GeoDataFrame)\n",
        "    .set_crs(epsg=4326)\n",
        ")\n",
        "\n",
        "# plot states with count of users\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "gdf_states.plot(ax=ax, color='gray', edgecolor='black')\n",
        "gdf_clients_stores.plot(\n",
        "    ax=ax,\n",
        "    markersize=1,\n",
        "    column='count',\n",
        "    legend=True,\n",
        "    cmap='viridis_r',\n",
        "    alpha=0.1\n",
        ")"
      ],
      "id": "b32dbe0f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análisis de tiendas por region\n"
      ],
      "id": "f5e0bfca"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# join users with states\n",
        "gdf_clients_stores_region = (\n",
        "    gpd.sjoin_nearest(\n",
        "        gdf_clients_stores.to_crs(\"EPSG:6372\"), gdf_states.to_crs(\"EPSG:6372\"),\n",
        "    )\n",
        ")\n",
        "\n",
        "# Map the states to their corresponding regions\n",
        "gdf_clients_stores_region['region'] = (\n",
        "    gdf_clients_stores_region['cve_name']\n",
        "    .map(lambda x: \n",
        "    next((region for region, states in nielsen_zones.items() if x.lower() in states),None))\n",
        ")\n",
        "\n",
        "# Function to print the top 5 and bottom 5 per region\n",
        "def top_bottom(region):\n",
        "    stores = (gdf_clients_stores_region[gdf_clients_stores_region[\"region\"]==region]\n",
        "        .sort_values(\"count\", ascending=False)\n",
        "        )[[\"name\", \"store_name\",\"cve_name\",\"count\"]]\n",
        "    stores.columns = [\"Nombre\", \"Formato\", \"Estado\", \"Clientes_reales\"]\n",
        "\n",
        "    ICD.display(f\"Top 5 tiendas {region}\")\n",
        "    ICD.display(stores.head(n=5))\n",
        "    ICD.display(f\"Bottom 5 tiendas {region}\")\n",
        "    ICD.display(stores.tail(n=5))\n",
        "\n",
        "for zone in nielsen_zones:\n",
        "    top_bottom(zone)\n",
        "    print(\"\\n\")"
      ],
      "id": "79c4af63",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análisis temporal\n",
        "\n",
        "# Distribución de usuarios por día de la semana"
      ],
      "id": "ada445b2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Obtain the number of users per day of the week\n",
        "potential_users = (\n",
        "    gdf_connections\n",
        "    .groupby(\"day_of_week\")\n",
        "    .agg(\n",
        "        count=(\"device_id\", \"count\")\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "# Sort the rows by day of the week\n",
        "sorted_weekdays = config['report']['weekdays']\n",
        "potential_users['day_of_week'] = pd.Categorical(potential_users['day_of_week'], sorted_weekdays)\n",
        "potential_users = potential_users.sort_values(\"day_of_week\")\n",
        "\n",
        "# Obtain the number of BAIT users per day of the week\n",
        "df_real_users = (\n",
        "    gdf_connections\n",
        "    [gdf_connections[\"raw_sim_operator_name\"] == \"BAIT\"]\n",
        "    .groupby(\"day_of_week\")\n",
        "    .agg(\n",
        "        count=(\"device_id\", \"count\")\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "# Sort the rows by day of the week\n",
        "df_real_users['day_of_week'] = pd.Categorical(df_real_users['day_of_week'], sorted_weekdays)\n",
        "df_real_users = df_real_users.sort_values(\"day_of_week\")\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(2, 1, figsize=(12, 12))\n",
        "# First plot\n",
        "axes[0].bar(potential_users['day_of_week'], potential_users['count'])\n",
        "axes[0].set_title('Número de usuarios por día de la semana')\n",
        "\n",
        "# Second plot\n",
        "axes[1].bar(df_real_users['day_of_week'], df_real_users['count'])\n",
        "axes[1].set_title('Número de usuarios BAIT por día de la semana')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "# Display\n",
        "plt.show()"
      ],
      "id": "3c2eb89e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tienda A"
      ],
      "id": "0f4513a3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def store_user_analysis(postal_code: str) -> None:\n",
        "    \"\"\"\n",
        "    Function to analyze the potential and real users of a store based on the postal code.\n",
        "    ---\n",
        "    postal_code: str\n",
        "        Postal code of the store.\n",
        "    \"\"\"\n",
        "    # Analyze the potential users of the store\n",
        "    df_store_potential_users = (\n",
        "        gdf_connections\n",
        "        [gdf_connections[\"postal_code\"] == postal_code]\n",
        "        .groupby(\"day_of_week\")\n",
        "        .agg(\n",
        "            count=(\"device_id\", \"count\")\n",
        "        )\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    # Sort the rows by day of the week\n",
        "    df_store_potential_users['day_of_week'] = (\n",
        "        pd.Categorical(df_store_potential_users['day_of_week'], sorted_weekdays)\n",
        "        )\n",
        "    df_store_potential_users = df_store_potential_users.sort_values(\"day_of_week\")\n",
        "\n",
        "    # Analyze the real users of the store\n",
        "    df_store_real_users = (\n",
        "        gdf_connections[\n",
        "            (gdf_connections[\"raw_sim_operator_name\"] == \"BAIT\") &\n",
        "            (gdf_connections[\"postal_code\"] == postal_code)\n",
        "        ]\n",
        "        .groupby(\"day_of_week\")\n",
        "        .agg(\n",
        "            count=(\"device_id\", \"count\")\n",
        "        )\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    # Sort the rows by day of the week\n",
        "    df_store_real_users['day_of_week'] = (pd\n",
        "        .Categorical(df_store_real_users['day_of_week'], sorted_weekdays)\n",
        "        )\n",
        "    df_store_real_users = df_store_real_users.sort_values(\"day_of_week\")\n",
        "\n",
        "    # Plot\n",
        "    # Comparison of potential users and real users\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(12, 12))\n",
        "\n",
        "    # Distribution of the number of users per day of the week\n",
        "    axes[0].bar(df_store_potential_users['day_of_week'], df_store_potential_users['count'])\n",
        "    axes[0].set_title('Número de usuarios por día de la semana')\n",
        "\n",
        "    # Distribution of the number of BAIT users per day of the week\n",
        "    axes[1].bar(df_store_real_users['day_of_week'], df_store_real_users['count'])\n",
        "    axes[1].set_title('Número de usuarios BAIT por día de la semana')\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Display\n",
        "    plt.show()\n",
        "\n",
        "# Obtain the number of BAIT clients per store based in their postal_code\n",
        "df_bait_users_per_store = (\n",
        "    gdf_clients_stores_region\n",
        "    .sort_values(\"count\", ascending=False)\n",
        "    [[\"name\", \"store_name\",\"cve_name\",\"count\"]]\n",
        "    )\n",
        "\n",
        "# columns in spanish for better understanding\n",
        "df_bait_users_per_store.columns = [\"Nombre\", \"Formato\", \"Estado\", \"Clientes_reales\"]\n",
        "\n",
        "# Obtain the postal code of the most and less crowded store\n",
        "top_postal_code = str(gdf_walmart[gdf_walmart[\"name\"] == df_bait_users_per_store.head(n=1)[\"Nombre\"][0]].postal_code.iloc[0])\n",
        "bottom_postal_code = str(gdf_walmart[gdf_walmart[\"name\"] == df_bait_users_per_store.tail(n=1)[\"Nombre\"].iloc[0]].postal_code.iloc[0])\n",
        "\n",
        "# User analysis for the most crowded store\n",
        "store_user_analysis(top_postal_code)"
      ],
      "id": "ca5e2788",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tienda B"
      ],
      "id": "55b66920"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# User analysis for the less crowded store\n",
        "store_user_analysis(bottom_postal_code)"
      ],
      "id": "9490a427",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}