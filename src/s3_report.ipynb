{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"BAIT\"\n",
        "format: \n",
        "    html:\n",
        "        echo: false\n",
        "        warning: false\n",
        "---"
      ],
      "id": "6288c6c9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reporte mensual por tienda\n",
        "\n",
        "¡Hola, Operador! Este reporte está creado para darte la visibilidad del estatus de los usuarios de Bait de tu operación. El objetivo del mismo es dar las herramientas mínimas necesarias para que puedas crear estrategias en torno a Bait y tu operación. Recuerda que somos el Operador Móvil Virtual Número 1 en México. ¡Vamos por las ventas!\n"
      ],
      "id": "36e27d8f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import geopandas as gpd\n",
        "from shapely import wkb\n",
        "from dotenv import load_dotenv\n",
        "import awswrangler as wr\n",
        "import os\n",
        "import yaml\n",
        "import boto3\n",
        "from IPython import display as ICD"
      ],
      "id": "0c2822af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configs\n",
        "# load environment variables with\n",
        "load_dotenv()\n",
        "\n",
        "# import config\n",
        "with open(\"../config.yaml\") as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# connect to AWS with credentials\n",
        "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "AWS_REGION = os.getenv(\"REGION\")\n",
        "BUCKET = os.getenv(\"BUCKET\")\n",
        "FOLDER = config[\"aws\"][\"folder\"]\n",
        "\n",
        "# connect to AWS\n",
        "session = boto3.Session(\n",
        "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
        "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
        "    region_name=AWS_REGION\n",
        ")\n",
        "s3 = session.client(\"s3\")"
      ],
      "id": "7fcee345",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# S1: Get User Data\n",
        "# get users data from S3\n",
        "gdf_users = (\n",
        "    wr.s3.read_parquet(\n",
        "        f\"s3://{BUCKET}/{FOLDER}/{config['aws']['users-file']}\"\n",
        "    )\n",
        "    .rename(columns={\"client_latitude\": \"latitude\", \"client_longitude\": \"longitude\"})\n",
        "    # convert to GeoDataFrame\n",
        "    .pipe(gpd.GeoDataFrame)\n",
        "    .assign(\n",
        "        geometry=lambda x: gpd.points_from_xy(x['longitude'], x['latitude'])\n",
        "    )\n",
        "    .set_crs(epsg=4326)\n",
        ")\n",
        "\n",
        "# S2: Wrangle Data\n",
        "# eliminate invalid values of raw_sim_operator_name\n",
        "non_valid_operators = config['report']['non-valid-operators']\n",
        "gdf_users = gdf_users[~gdf_users[\"raw_sim_operator_name\"].isin(non_valid_operators)]\n",
        "\n",
        "# standarize the name of Megacable\n",
        "gdf_users.loc[\n",
        "    gdf_users[\"raw_sim_operator_name\"].isin([\"Mega 4.5G\", \"Mega4.5G\"]), \"raw_sim_operator_name\"\n",
        "    ] = \"Megacable\""
      ],
      "id": "ec0eda9d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# S1: Get Shape Data\n",
        "# download shapefile of states\n",
        "gdf_states = (\n",
        "    wr.s3.read_parquet(\n",
        "        f\"s3://{BUCKET}/{FOLDER}/{config['aws']['states-file']}\"\n",
        "    )\n",
        "    # pass geometry column from binary to geometry\n",
        "    .assign(geometry=lambda x: x['geometry'].apply(wkb.loads))\n",
        "    .pipe(gpd.GeoDataFrame)\n",
        "    .set_crs(epsg=4326)\n",
        "    .rename(columns={\"CODIGO\": \"cve_ent\", \"ESTADO\": \"cve_name\"})\n",
        "    .assign(\n",
        "        cve_ent=lambda x: x['cve_ent'].str[-2:],\n",
        "        cve_name=lambda x: x['cve_name'].str.lower()\n",
        "    )\n",
        "    .sort_values('cve_ent', ignore_index=True)\n",
        ")\n",
        "\n",
        "# S2: Wrangle Data\n",
        "# get data of walmart stores\n",
        "re_walmart = r\"(walmart|wal mart|superama|waltmart)\"\n",
        "re_sams = r\"(sams|sam's|sam s|sam's club|sam s club|sam'sclub|sam sclub|sam club|mi bodega)\"\n",
        "re_bodega = r\"(bodega aurrera|bodega|aurrera|ba|boa|\\$b|mb|b )\"\n",
        "re_supercenter = r\"(supercenter|super center)\"\n",
        "\n",
        "# get walmart stores\n",
        "gdf_walmart = (\n",
        "    wr.s3.read_csv(\n",
        "        f\"s3://{BUCKET}/{FOLDER}/{config['aws']['walmart-file']}\"\n",
        "    )\n",
        "    .assign(\n",
        "        geometry=lambda x: gpd.points_from_xy(x['longitude'], x['latitude']),\n",
        "        # get bodega aurrera or walmart or sams in name\n",
        "        store_name=lambda x: np.select(\n",
        "            [\n",
        "                x['name'].str.contains(re_bodega, case=False),\n",
        "                x['name'].str.contains(re_walmart, case=False),\n",
        "                x['name'].str.contains(re_sams, case=False),\n",
        "                x['name'].str.contains(re_supercenter, case=False)\n",
        "            ],\n",
        "            ['bodega aurrera', 'walmart', 'sams', 'supercenter'],\n",
        "            default='other'\n",
        "        )\n",
        "    )\n",
        "    .pipe(gpd.GeoDataFrame, crs=\"EPSG:4326\")\n",
        "    .query(\"store_name != 'other'\")\n",
        "    .loc[:, [\n",
        "             'id', 'store_name', 'name', 'staff_stratum_description',\n",
        "             'postal_code', 'cve_ent', 'cve_mun', 'geometry'\n",
        "            ]]\n",
        ")"
      ],
      "id": "1fa8eaf4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# S1: Get Connections Data\n",
        "# get connections data from S3\n",
        "gdf_connections = (\n",
        "    wr.s3.read_parquet(\n",
        "        f\"s3://{BUCKET}/{FOLDER}/{config['aws']['connections-file']}\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# S2: Wrangle Data\n",
        "# obtain the day of the week of each test\n",
        "gdf_connections['day_of_week'] = gdf_connections['result_date'].dt.day_name()\n",
        "\n",
        "# Translate the days to Spanish\n",
        "def days_to_Spanish(argument):\n",
        "    days = {\n",
        "        \"Monday\": \"Lunes\",\n",
        "        \"Tuesday\": \"Martes\",\n",
        "        \"Wednesday\": \"Miércoles\",\n",
        "        \"Thursday\": \"Jueves\",\n",
        "        \"Friday\": \"Viernes\",\n",
        "        \"Saturday\": \"Sábado\",\n",
        "        \"Sunday\": \"Domingo\"\n",
        "    }\n",
        "    return days.get(argument, \"error\")\n",
        "\n",
        "gdf_connections['day_of_week'] = gdf_connections['day_of_week'].apply(days_to_Spanish)"
      ],
      "id": "44bce59a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Participación de mercado\n",
        "\n",
        "Zonas Nielsen:\n",
        "\n",
        "-   BAJÍO: Aguascalientes, Jalisco, Guanajuato, Colima, Michoacán\n",
        "\n",
        "-   PACÍFICO: Baja California, Baja California Sur, Sinaloa, Sonora, Nayarit\n",
        "\n",
        "-   NORTE: Chihuahua, Coahuila, Durango, Nuevo León, San Luis Potosí, Tamaulipas, Zacatecas\n",
        "\n",
        "-   SURESTE: Campeche, Chiapas, Oaxaca, Quintana Roo, Tabasco, Veracruz, Yucatán\n",
        "\n",
        "-   CENTRO: CDMX, Guerrero, Hidalgo, EDOMEX, Morelos, Puebla, Querétaro, Tlaxcala\n"
      ],
      "id": "cf7ac8e0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Join Data\n",
        "# join users with states\n",
        "tbl_users_state = (\n",
        "    gpd.sjoin_nearest(\n",
        "        gdf_users.to_crs(\"EPSG:6372\"), gdf_states.to_crs(\"EPSG:6372\"),\n",
        "    )\n",
        "    .drop_duplicates(subset=[\"device_id\"])\n",
        "    .filter([\"device_id\", \"postal_code\", \"raw_sim_operator_name\", \"cve_name\"])\n",
        ")\n",
        "\n",
        "# define the dictionary\n",
        "nielsen_zones = config['report']['nielsen_zones']\n",
        "\n",
        "# map the states to their corresponding regions\n",
        "tbl_users_state['region'] = (\n",
        "    tbl_users_state['cve_name']\n",
        "    .map(\n",
        "        lambda x: next((region for region, states in nielsen_zones.items() if x.lower() in states), None)\n",
        "        )\n",
        ")\n",
        "\n",
        "# droup by 'raw_sim_operator_name' and count 'device_id', then sort and get the top 10\n",
        "top_operators = (\n",
        "    tbl_users_state\n",
        "    .groupby([\"raw_sim_operator_name\"])['device_id']\n",
        "    .count()\n",
        "    .sort_values(ascending=False)\n",
        "    .head(10)\n",
        "    .reset_index()\n",
        "    [\"raw_sim_operator_name\"]\n",
        ")\n",
        "\n",
        "# Wrangle\n",
        "tbl_users_state.loc[~tbl_users_state[\"raw_sim_operator_name\"].isin(top_operators), \"raw_sim_operator_name\"] = \"other\"\n",
        "# group by 'raw_sim_operator_name' and count 'device_id'\n",
        "df_top_operator = tbl_users_state.groupby([\"raw_sim_operator_name\", \"region\"])['device_id'].count().reset_index()\n",
        "# Get market share\n",
        "df_top_operator[\"market_share\"] = df_top_operator.groupby(\"region\")[\"device_id\"].transform(lambda x: x / x.sum())\n",
        "# Pivot the DataFrame for the stacked bar chart\n",
        "pivot_df = df_top_operator.pivot(index='region', columns='raw_sim_operator_name', values='market_share')\n",
        "# Fill NaN values with 0\n",
        "pivot_df = pivot_df.fillna(0)\n",
        "\n",
        "# Filter the market share of bait in each region and select the maximum and minimum\n",
        "bait_share = df_top_operator[df_top_operator[\"raw_sim_operator_name\"]==\"BAIT\"]\n",
        "# Maximum and minimum share\n",
        "max_p = np.max(bait_share.market_share)\n",
        "min_p = np.min(bait_share.market_share)\n",
        "# Obtain the best and worst region based on the share market\n",
        "best_region = bait_share[bait_share[\"market_share\"]==max_p].region.iloc[0]\n",
        "worst_region = bait_share[bait_share[\"market_share\"]==min_p].region.iloc[0]\n",
        "best_region_p = round(max_p*100,2)\n",
        "worst_region_p = round(min_p*100,2)\n",
        "\n",
        "\n",
        "# Plot\n",
        "# stacked bar chart\n",
        "pivot_df.plot(kind='bar', stacked=True, figsize=(12, 8), colormap='tab20')\n",
        "# add labels and title\n",
        "plt.xlabel('Estado')\n",
        "plt.ylabel('Device ID Count')\n",
        "plt.title('Top 10 SIM Operators by Device ID Count per Estado')\n",
        "plt.legend(title='SIM Operator Name', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "# y lim\n",
        "plt.ylim(0, 1)\n",
        "# y in percentage\n",
        "plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_yticks()])\n",
        "# display\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "dc0fa68a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tomando en cuenta a todos los Operadores Móviles Virtuales (OMVs) de la red de ALTÁN, podemos visualizar la participación de Bait vs los otros operadores del mercado. Es evidente que en todas las zonas del país Bait es el OMV número 1. La zona con mayor participación es `{python} best_region` con un `{python} best_region_p`%, por otro lado, la zona con menor participación es `{python} worst_region` con un `{python} worst_region_p`%. Con esto, se recomienda replicar la estrategia de venta que está generado la zona `{python} best_region` en `{python} worst_region` .\n",
        "\n",
        "Por otro lado, a nivel nacional los siguientes 4 OMVs con mayor participación de mercado son `{python} top_operators[1]`, `{python} top_operators[2]`, `{python} top_operators[3]` y `{python} top_operators[4]`. Es imperante entender qué están haciendo estos operadores en las zonas que están teniendo más penetración para que Bait mantenga su posición en el mercado.\n",
        "\n",
        "# Presencia nacional\n",
        "\n",
        "En el siguiente mapa se puede observar la presencia nacional de Bait en cada una de las tiendas (puntos de venta). El color de la burbuja nos indica el número de clientes Bait por tienda. Para decidir si un cliente Bait es de una tienda en específico a cada conexión registrada en la base de datos se le asigna la tienda más cercana. Posteriormente, a cada usuario registrado, se le asigna la tienda donde se hayan registrado el mayor número de conexiones.\n"
      ],
      "id": "f99164af"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Select only BAIT users\n",
        "gdf_bait_users = gdf_users[gdf_users[\"raw_sim_operator_name\"] == \"BAIT\"]\n",
        "\n",
        "# Join users with stores getting the closest store\n",
        "gdf_clients_stores = (\n",
        "    gpd.sjoin_nearest(\n",
        "        gdf_bait_users.to_crs(\"EPSG:6372\"), gdf_walmart.to_crs(\"EPSG:6372\"),\n",
        "    )\n",
        "    .drop_duplicates(subset=[\"device_id\"])\n",
        "    .groupby([\"name\", \"store_name\", \"id\", \"cve_ent\", \"cve_mun\"])\n",
        "    .agg(\n",
        "        count=(\"device_id\", \"count\")\n",
        "    )\n",
        "    .reset_index()\n",
        "    .sort_values(\"count\", ascending=False)\n",
        "    .merge(\n",
        "        gdf_walmart.loc[:, [\"id\", \"geometry\"]],\n",
        "        on=\"id\",\n",
        "        how=\"left\"\n",
        "    )\n",
        "    .pipe(gpd.GeoDataFrame)\n",
        "    .set_crs(epsg=4326)\n",
        "    .assign(\n",
        "        index=lambda x: (x['count'] - x['count'].min()) / (x['count'].max() - x['count'].min())\n",
        "    )\n",
        ")\n",
        "\n",
        "# plot states with count of users\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "gdf_states.plot(ax=ax, color='lightgray', edgecolor='black')\n",
        "gdf_clients_stores.plot(\n",
        "    ax=ax,\n",
        "    markersize=1.5,\n",
        "    column='index',\n",
        "    cmap='magma_r',\n",
        "    legend=True,\n",
        "    alpha=1\n",
        ")\n",
        "# title\n",
        "plt.title('Concentración de usuarios Bait por tienda')\n",
        "# x and y ticks off\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "# legend more readable, loc in bottom \n",
        "\n",
        "# display\n",
        "plt.show()"
      ],
      "id": "b08b0b3f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como se puede observar el centro del país es donde se tiene un mayor número de clientes Bait, lo cual está relacionado a la cantidad de unidades en la región. Lo anterior nos confirma la alta dependencia que tenemos de los puntos de venta físicos para seguir generando nuevos usuarios, le sigue la región sureste y por último la región norte, la cual tiene el menor número de clientes activos Bait.\n",
        "\n",
        "# Análisis de tiendas por region\n"
      ],
      "id": "974f3973"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bodega_top = (gdf_clients_stores[gdf_clients_stores[\"store_name\"]==\"bodega aurrera\"]\n",
        "    .sort_values(\"count\", ascending=False)\n",
        "    .name\n",
        "    .iloc[0]\n",
        ")\n",
        "\n",
        "walmart_top = (gdf_clients_stores[(gdf_clients_stores[\"store_name\"]==\"supercenter\") |\n",
        "    (gdf_clients_stores[\"store_name\"]==\"walmart\")]\n",
        "    .sort_values(\"count\", ascending=False)\n",
        "    .name\n",
        "    .iloc[0]\n",
        ")\n",
        "\n",
        "sams_top = (gdf_clients_stores[gdf_clients_stores[\"store_name\"]==\"sams\"]\n",
        "    .sort_values(\"count\", ascending=False)\n",
        "    .name\n",
        "    .iloc[0]\n",
        ")"
      ],
      "id": "ebc4a775",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Es importante replicar las buenas prácticas que están realizando las tiendas con mayor número de usuarios, asimismo, es imperante que las tiendas con menor número de usuarios ejecuten nuevas estrategias para no distanciarse más de las mejores. A nivel nacional las tiendas top por formato son:\n",
        "\n",
        "-   Bodega Aurrera: `{python} bodega_top`\n",
        "-   Walmart Supercenter: `{python} walmart_top`\n",
        "-   Sams: `{python} sams_top`\n",
        "\n",
        "A continuación, se verán las 5 tiendas Top vs 5 tiendas Bottom de cada una de las Zonas Nielsen del país:\n"
      ],
      "id": "8b0eb3bf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# join users with states\n",
        "gdf_clients_stores_region = (\n",
        "    gpd.sjoin_nearest(\n",
        "        gdf_clients_stores.to_crs(\"EPSG:6372\"), gdf_states.to_crs(\"EPSG:6372\"),\n",
        "    )\n",
        ")\n",
        "\n",
        "# Map the states to their corresponding regions\n",
        "gdf_clients_stores_region['region'] = (\n",
        "    gdf_clients_stores_region['cve_name']\n",
        "    .map(lambda x: \n",
        "    next((region for region, states in nielsen_zones.items() if x.lower() in states),None))\n",
        ")\n",
        "\n",
        "# Function to print the top 5 and bottom 5 per region\n",
        "def top_bottom(region):\n",
        "    stores = (gdf_clients_stores_region[gdf_clients_stores_region[\"region\"]==region]\n",
        "        .sort_values(\"count\", ascending=False)\n",
        "        )[[\"name\", \"store_name\",\"cve_name\",\"count\"]]\n",
        "    stores.columns = [\"Nombre\", \"Formato\", \"Estado\", \"Clientes_reales\"]\n",
        "\n",
        "    ICD.display(f\"Top 5 tiendas {region}\")\n",
        "    ICD.display(stores.head(n=5))\n",
        "    ICD.display(f\"Bottom 5 tiendas {region}\")\n",
        "    ICD.display(stores.tail(n=5))\n",
        "\n",
        "for zone in nielsen_zones:\n",
        "    top_bottom(zone)\n",
        "    print(\"\\n\")"
      ],
      "id": "91b42159",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análisis temporal\n",
        "\n",
        "# Distribución de usuarios por día de la semana\n"
      ],
      "id": "b7aef435"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Obtain the number of users per day of the week\n",
        "potential_users = (\n",
        "    gdf_connections\n",
        "    .groupby(\"day_of_week\")\n",
        "    .agg(\n",
        "        count=(\"device_id\", \"count\")\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "# Sort the rows by day of the week\n",
        "sorted_weekdays = config['report']['weekdays']\n",
        "potential_users['day_of_week'] = pd.Categorical(potential_users['day_of_week'], sorted_weekdays)\n",
        "potential_users = potential_users.sort_values(\"day_of_week\")\n",
        "\n",
        "# Filter the day with more traffic\n",
        "max_traffic = max(potential_users[\"count\"])\n",
        "best_day = (\n",
        "    potential_users[potential_users[\"count\"]== max_traffic]\n",
        "    .day_of_week\n",
        "    .iloc[0]\n",
        ")\n",
        "\n",
        "# Filter the day with less traffic\n",
        "less_traffic = min(potential_users[\"count\"])\n",
        "worst_day = (\n",
        "    potential_users[potential_users[\"count\"]== less_traffic]\n",
        "    .day_of_week\n",
        "    .iloc[0]\n",
        ")\n",
        "\n",
        "# Obtain the number of BAIT users per day of the week\n",
        "df_real_users = (\n",
        "    gdf_connections\n",
        "    [gdf_connections[\"raw_sim_operator_name\"] == \"BAIT\"]\n",
        "    .groupby(\"day_of_week\")\n",
        "    .agg(\n",
        "        count=(\"device_id\", \"count\")\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "# Sort the rows by day of the week\n",
        "df_real_users['day_of_week'] = pd.Categorical(df_real_users['day_of_week'], sorted_weekdays)\n",
        "df_real_users = df_real_users.sort_values(\"day_of_week\")\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(2, 1, figsize=(6, 6))\n",
        "# First plot\n",
        "axes[0].bar(potential_users['day_of_week'], potential_users['count'])\n",
        "axes[0].set_title('Número de usuarios por día de la semana')\n",
        "\n",
        "# Second plot\n",
        "axes[1].bar(df_real_users['day_of_week'], df_real_users['count'])\n",
        "axes[1].set_title('Número de usuarios BAIT por día de la semana')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "# Display\n",
        "plt.show()"
      ],
      "id": "f18ef1ac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Debido a que se tienen todas las conexiones de los usuarios de todos los OMVs, podemos identificar clientes potenciales para cada tienda con base en el número de usuarios que están activos en el mismo código postal de la unidad. Por ello, podemos identificar qué día de la semana hay más clientes potenciales vs el día con menor número. Por otro lado, se puede visualizar el mismo comportamiento, pero con el número de clientes Bait. Al realizar este contraste, podemos ver que el día que más usuarios potenciales están cercanos a la unidad es el `{python} best_day`, por el contrario, el día con menos usuarios potenciales, en el cual se podrían crear distintas estrategias para incentivar la presencia de más clientes es el `{python} worst_day`.\n"
      ],
      "id": "38e9d7d4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Obtain the number of BAIT clients per store based in their postal_code\n",
        "df_bait_users_per_store = (\n",
        "    gdf_clients_stores_region\n",
        "    .sort_values(\"count\", ascending=False)\n",
        "    [[\"name\", \"store_name\",\"cve_name\",\"count\"]]\n",
        "    )\n",
        "\n",
        "# columns in spanish for better understanding\n",
        "df_bait_users_per_store.columns = [\"Nombre\", \"Formato\", \"Estado\", \"Clientes_reales\"]\n",
        "\n",
        "# Obtain the postal code of the most and less crowded store\n",
        "top_postal_code = str(gdf_walmart[gdf_walmart[\"name\"] == df_bait_users_per_store.head(n=1)[\"Nombre\"][0]].postal_code.iloc[0])\n",
        "bottom_postal_code = str(gdf_walmart[gdf_walmart[\"name\"] == df_bait_users_per_store.tail(n=1)[\"Nombre\"].iloc[0]].postal_code.iloc[0])"
      ],
      "id": "a6bfeacd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}